{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bc820b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import h5py\n",
    "import threading\n",
    "import time\n",
    "import wfdb\n",
    "import neurokit2 as nk\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import butter, filtfilt, find_peaks, convolve\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "from sklearn.utils import class_weight\n",
    "from skimage.transform import resize\n",
    "from collections import deque\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9983734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rri(qrs_raw_ind, fs):\n",
    "    rri = np.diff(qrs_raw_ind) / fs  # convert indices to time in seconds\n",
    "    rri_milliseconds = rri * 1000\n",
    "    return rri_milliseconds\n",
    "\n",
    "def neurakit_rri(record, fs):\n",
    "    signals, info = nk.ecg_process(record, sampling_rate=fs)\n",
    "    rpeaks = info[\"ECG_R_Peaks\"]\n",
    "    # rpeak_amplitudes = record[rpeaks]\n",
    "    rri = get_rri(rpeaks, fs)\n",
    "    return rri\n",
    "\n",
    "def normalize_to_gray_scale(matrix):\n",
    "    min_val = np.min(matrix)\n",
    "    max_val = np.max(matrix)\n",
    "    normalized_matrix = (matrix - min_val) / (max_val - min_val + 1e-8)  # Avoid division by zero\n",
    "    return (normalized_matrix*255).astype(np.uint8)\n",
    "\n",
    "def rp_plot(rri, delay, embedding_dim):\n",
    "    N= len(rri)\n",
    "    Nrp = N - (embedding_dim - 1) * delay\n",
    "    embedded_rri = np.array([rri[i: i + embedding_dim * delay: delay] for i in range(Nrp)])\n",
    "    distances = squareform(pdist(embedded_rri, metric='euclidean'))\n",
    "    return distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c57451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stream] Processing chunk from 0 to 1920\n",
      "[Stream] Added samples. Buffer size: 1920\n",
      "[Stream] Processing chunk from 1920 to 3840\n",
      "[Stream] Added samples. Buffer size: 3840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 15:33:21.811740: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Predicted class: 1 with confidence 0.85\n",
      "Stopping threads...\n"
     ]
    }
   ],
   "source": [
    "fs = 128\n",
    "window_size = 128 * 30\n",
    "chunk_size = 128 * 15\n",
    "length_ecg= 0\n",
    "\n",
    "buffer = deque(maxlen=window_size)\n",
    "lock = threading.Lock()\n",
    "model_path = \"/Users/weijithwimalasiri/Desktop/WARN/NN_weights/WEIGHTS.hdf5\"\n",
    "record  = wfdb.rdrecord('/Users/weijithwimalasiri/Desktop/JustForFun/RPS/physionet.org/files/afpdb/1.0.0/p01')\n",
    "ecg = record.p_signal[:, 0]  \n",
    "total_samples = len(ecg)\n",
    "fs = record.fs\n",
    "model = load_model(model_path)\n",
    "stream_index = [0]\n",
    "stop_threads = threading.Event()\n",
    "\n",
    "def stream_data(ecg, total_samples):\n",
    "    global buffer\n",
    "    while stream_index[0] + chunk_size <=  total_samples and not stop_threads.is_set():\n",
    "        try: \n",
    "            with lock: \n",
    "                data_chunk = ecg[stream_index[0]:stream_index[0] + chunk_size]\n",
    "                print(f\"[Stream] Processing chunk from {stream_index[0]} to {stream_index[0] + chunk_size}\")\n",
    "                buffer.extend(data_chunk)\n",
    "                stream_index[0] += chunk_size\n",
    "                print(f\"[Stream] Added samples. Buffer size: {len(buffer)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Inference error: {e}\")\n",
    "        time.sleep(15)\n",
    "\n",
    "def inference_pipeline(model, img_size=(224, 224)):\n",
    "    last_pred_index = -1 \n",
    "    while not stop_threads.is_set():\n",
    "        try: \n",
    "            with lock:\n",
    "                if len(buffer) == window_size and stream_index[0] != last_pred_index:\n",
    "                    window = np.array(buffer)\n",
    "\n",
    "                    rri = neurakit_rri(window, fs)\n",
    "                    distances = rp_plot(rri, delay= 3, embedding_dim=3)\n",
    "                    rp_gray = normalize_to_gray_scale(distances)\n",
    "                    rp_img = resize(rp_gray, img_size, anti_aliasing=True, preserve_range=True).astype(np.uint8)\n",
    "                    input_tensor = np.expand_dims(rp_img, axis=(0, -1)) \n",
    "\n",
    "                    pred = model.predict(input_tensor) \n",
    "                    pred_class = np.argmax(pred)\n",
    "                    confidence = pred[0][pred_class]\n",
    "                    print(f\"Predicted class: {pred_class} with confidence {confidence:.2f}\")\n",
    "                    last_pred_index = stream_index[0]\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Inference error: {e}\")\n",
    "        time.sleep(15)  \n",
    "\n",
    "threading.Thread(target=stream_data, args=(ecg, total_samples), daemon=True).start()\n",
    "threading.Thread(target=inference_pipeline, args=(model,), daemon=True).start()\n",
    "\n",
    "# Keep main thread alive\n",
    "try:\n",
    "    while stream_index[0] + chunk_size <= total_samples:\n",
    "        time.sleep(1)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopping threads...\")\n",
    "    stop_threads.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b816787",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 128\n",
    "window_size = 128 * 30\n",
    "chunk_size = 128 * 15\n",
    "length_ecg= 0\n",
    "\n",
    "buffer = deque(maxlen=window_size)\n",
    "lock = threading.Lock()\n",
    "model_path = \"/Users/weijithwimalasiri/Desktop/WARN/NN_weights/WEIGHTS.hdf5\"\n",
    "record  = wfdb.rdrecord('/Users/weijithwimalasiri/Desktop/JustForFun/RPS/physionet.org/files/afpdb/1.0.0/p01')\n",
    "ecg = record.p_signal[:, 0]  \n",
    "total_samples = len(ecg)\n",
    "fs = record.fs\n",
    "\n",
    "# Stream data and inference without threads\n",
    "for start_idx in range(0, total_samples - chunk_size + 1, chunk_size):\n",
    "    data_chunk = ecg[start_idx:start_idx + chunk_size]\n",
    "    buffer.extend(data_chunk)\n",
    "    print(f\"[Stream] Processing chunk from {start_idx} to {start_idx + chunk_size}\")\n",
    "    print(f\"[Stream] Added samples. Buffer size: {len(buffer)}\")\n",
    "\n",
    "    if len(buffer) == window_size:\n",
    "        window = np.array(buffer)\n",
    "        rri = neurakit_rri(window, fs)\n",
    "        distances = rp_plot(rri, delay=3, embedding_dim=3)\n",
    "        rp_gray = normalize_to_gray_scale(distances)\n",
    "        rp_img = resize(rp_gray, (224, 224), anti_aliasing=True, preserve_range=True).astype(np.uint8)\n",
    "        input_tensor = np.expand_dims(rp_img, axis=(0, -1))\n",
    "        pred = model.predict(input_tensor)\n",
    "        pred_class = np.argmax(pred)\n",
    "        confidence = pred[0][pred_class]\n",
    "        print(f\"Predicted class: {pred_class} with confidence {confidence:.2f}\")\n",
    "model = load_model(model_path)\n",
    "stream_index = [0]\n",
    "stop_threads = threading.Event()\n",
    "\n",
    "def stream_data(ecg, total_samples):\n",
    "    global buffer\n",
    "    while stream_index[0] + chunk_size <=  total_samples and not stop_threads.is_set():\n",
    "        try: \n",
    "            with lock: \n",
    "                data_chunk = ecg[stream_index[0]:stream_index[0] + chunk_size]\n",
    "                print(f\"[Stream] Processing chunk from {stream_index[0]} to {stream_index[0] + chunk_size}\")\n",
    "                buffer.extend(data_chunk)\n",
    "                stream_index[0] += chunk_size\n",
    "                print(f\"[Stream] Added samples. Buffer size: {len(buffer)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Inference error: {e}\")\n",
    "        time.sleep(15)\n",
    "\n",
    "def inference_pipeline(model, img_size=(224, 224)):\n",
    "    last_pred_index = -1 \n",
    "    while not stop_threads.is_set():\n",
    "        try: \n",
    "            with lock:\n",
    "                if len(buffer) == window_size and stream_index[0] != last_pred_index:\n",
    "                    window = np.array(buffer)\n",
    "\n",
    "                    rri = neurakit_rri(window, fs)\n",
    "                    distances = rp_plot(rri, delay= 3, embedding_dim=3)\n",
    "                    rp_gray = normalize_to_gray_scale(distances)\n",
    "                    rp_img = resize(rp_gray, img_size, anti_aliasing=True, preserve_range=True).astype(np.uint8)\n",
    "                    input_tensor = np.expand_dims(rp_img, axis=(0, -1)) \n",
    "\n",
    "                    pred = model.predict(input_tensor) \n",
    "                    pred_class = np.argmax(pred)\n",
    "                    confidence = pred[0][pred_class]\n",
    "                    print(f\"Predicted class: {pred_class} with confidence {confidence:.2f}\")\n",
    "                    last_pred_index = stream_index[0]\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Inference error: {e}\")\n",
    "        time.sleep(15)  \n",
    "\n",
    "threading.Thread(target=stream_data, args=(ecg, total_samples), daemon=True).start()\n",
    "threading.Thread(target=inference_pipeline, args=(model,), daemon=True).start()\n",
    "\n",
    "# Keep main thread alive\n",
    "try:\n",
    "    while stream_index[0] + chunk_size <= total_samples:\n",
    "        time.sleep(1)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopping threads...\")\n",
    "    stop_threads.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c9f0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(folder, files, batch_size):\n",
    "    while True:\n",
    "        random.shuffle(files)\n",
    "        for current_file in files:\n",
    "            with h5py.File(os.path.join(folder, current_file), 'r') as hf:\n",
    "                x = tf.convert_to_tensor(hf['x'])\n",
    "                y = tf.convert_to_tensor(hf['y'])\n",
    "                for i in range(0, len(y), batch_size):\n",
    "                    x_batch = x[i:i + batch_size]\n",
    "                    y_batch = y[i:i + batch_size]\n",
    "                    if len(x_batch) == batch_size:\n",
    "                        yield x_batch, y_batch\n",
    "\n",
    "def get_model(input_shape = (224, 224, 1), lr=1e-5):\n",
    "    base_model = tf.keras.applications.EfficientNetV2S(\n",
    "        include_top=False,\n",
    "        weights = None, \n",
    "        input_shape=input_shape,\n",
    "    )\n",
    "\n",
    "    x = base_model.output\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    predictions = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy', 'AUC'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ef947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/Users/weijithwimalasiri/Desktop/WARN/NN_weights/WEIGHTS.hdf5\"\n",
    "model = load_model(model_path)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991a7e10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
